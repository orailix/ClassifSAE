{
    "category": "World",
    "Percentage ablation of the segment": 25,
    "Ablated features": [
        7
    ],
    "Global Absolute Accuracy change": -0.07355266809463501,
    "Global Total Variation Distance with regard to original predictions": 0.07018795609474182,
    "Global label-flip rate": 0.07565789669752121,
    "number real samples_0": 1900,
    "true matches_0": 1207,
    "number predicted samples_0": 1253,
    "recall_0": 0.6352631578947369,
    "precision_0": 0.9632881085395052,
    "f1-score_0": 0.7656200444021568,
    "number real samples_1": 1900,
    "true matches_1": 1872,
    "number predicted samples_1": 1913,
    "recall_1": 0.9852631578947368,
    "precision_1": 0.9785676947203346,
    "f1-score_1": 0.981904012588513,
    "number real samples_2": 1900,
    "true matches_2": 1712,
    "number predicted samples_2": 2470,
    "recall_2": 0.9010526315789473,
    "precision_2": 0.6931174089068826,
    "f1-score_2": 0.7835240274599542,
    "number real samples_3": 1900,
    "true matches_3": 1761,
    "number predicted samples_3": 1964,
    "recall_3": 0.9268421052631579,
    "precision_3": 0.8966395112016293,
    "f1-score_3": 0.9114906832298136
}