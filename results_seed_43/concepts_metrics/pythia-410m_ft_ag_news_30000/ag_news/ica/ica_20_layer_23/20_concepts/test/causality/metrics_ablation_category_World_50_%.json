{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        0,
        5
    ],
    "Global Absolute Accuracy change": -0.013157904148101807,
    "Global Total Variation Distance with regard to original predictions": 0.03936738893389702,
    "Global label-flip rate": 0.035394735634326935,
    "number real samples_0": 1900,
    "true matches_0": 1690,
    "number predicted samples_0": 1727,
    "recall_0": 0.8894736842105263,
    "precision_0": 0.9785755645628257,
    "f1-score_0": 0.931899641577061,
    "number real samples_1": 1900,
    "true matches_1": 1876,
    "number predicted samples_1": 1921,
    "recall_1": 0.9873684210526316,
    "precision_1": 0.9765747006767309,
    "f1-score_1": 0.9819419000261711,
    "number real samples_2": 1900,
    "true matches_2": 1706,
    "number predicted samples_2": 2004,
    "recall_2": 0.8978947368421053,
    "precision_2": 0.8512974051896207,
    "f1-score_2": 0.8739754098360656,
    "number real samples_3": 1900,
    "true matches_3": 1741,
    "number predicted samples_3": 1948,
    "recall_3": 0.9163157894736842,
    "precision_3": 0.8937371663244353,
    "f1-score_3": 0.9048856548856549
}