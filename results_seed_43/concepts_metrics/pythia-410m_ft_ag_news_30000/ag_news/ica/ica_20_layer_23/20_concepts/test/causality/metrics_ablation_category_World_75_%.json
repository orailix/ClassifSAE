{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        0,
        5,
        4
    ],
    "Global Absolute Accuracy change": -0.017631590366363525,
    "Global Total Variation Distance with regard to original predictions": 0.045290976762771606,
    "Global label-flip rate": 0.03776315972208977,
    "number real samples_0": 1900,
    "true matches_0": 1659,
    "number predicted samples_0": 1699,
    "recall_0": 0.8731578947368421,
    "precision_0": 0.9764567392583873,
    "f1-score_0": 0.9219227563212004,
    "number real samples_1": 1900,
    "true matches_1": 1876,
    "number predicted samples_1": 1924,
    "recall_1": 0.9873684210526316,
    "precision_1": 0.975051975051975,
    "f1-score_1": 0.9811715481171548,
    "number real samples_2": 1900,
    "true matches_2": 1701,
    "number predicted samples_2": 2022,
    "recall_2": 0.8952631578947369,
    "precision_2": 0.841246290801187,
    "f1-score_2": 0.8674145843957165,
    "number real samples_3": 1900,
    "true matches_3": 1743,
    "number predicted samples_3": 1955,
    "recall_3": 0.9173684210526316,
    "precision_3": 0.8915601023017903,
    "f1-score_3": 0.9042801556420234
}