{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        3
    ],
    "Global Absolute Accuracy change": -0.03671056032180786,
    "Global Total Variation Distance with regard to original predictions": 0.045133788138628006,
    "Global label-flip rate": 0.045394737273454666,
    "number real samples_0": 1900,
    "true matches_0": 1390,
    "number predicted samples_0": 1446,
    "recall_0": 0.7315789473684211,
    "precision_0": 0.9612724757952974,
    "f1-score_0": 0.8308427973699941,
    "number real samples_1": 1900,
    "true matches_1": 1858,
    "number predicted samples_1": 2207,
    "recall_1": 0.9778947368421053,
    "precision_1": 0.8418667874943362,
    "f1-score_1": 0.9047966885804724,
    "number real samples_2": 1900,
    "true matches_2": 1641,
    "number predicted samples_2": 1904,
    "recall_2": 0.8636842105263158,
    "precision_2": 0.8618697478991597,
    "f1-score_2": 0.8627760252365931,
    "number real samples_3": 1900,
    "true matches_3": 1743,
    "number predicted samples_3": 2043,
    "recall_3": 0.9173684210526316,
    "precision_3": 0.8531571218795888,
    "f1-score_3": 0.8840984022318031
}