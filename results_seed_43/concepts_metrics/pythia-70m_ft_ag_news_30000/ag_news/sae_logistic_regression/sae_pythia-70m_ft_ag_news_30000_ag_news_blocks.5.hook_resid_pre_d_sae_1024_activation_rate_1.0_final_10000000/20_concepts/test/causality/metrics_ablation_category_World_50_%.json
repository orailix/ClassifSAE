{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        525,
        896,
        553,
        92
    ],
    "Global Absolute Accuracy change": -0.19723689556121826,
    "Global Total Variation Distance with regard to original predictions": 0.22425854206085205,
    "Global label-flip rate": 0.22802631556987762,
    "number real samples_0": 1900,
    "true matches_0": 136,
    "number predicted samples_0": 150,
    "recall_0": 0.07157894736842105,
    "precision_0": 0.9066666666666666,
    "f1-score_0": 0.13268292682926827,
    "number real samples_1": 1900,
    "true matches_1": 1864,
    "number predicted samples_1": 2088,
    "recall_1": 0.9810526315789474,
    "precision_1": 0.89272030651341,
    "f1-score_1": 0.9348044132397192,
    "number real samples_2": 1900,
    "true matches_2": 1713,
    "number predicted samples_2": 3206,
    "recall_2": 0.901578947368421,
    "precision_2": 0.5343106674984405,
    "f1-score_2": 0.6709753231492362,
    "number real samples_3": 1900,
    "true matches_3": 1702,
    "number predicted samples_3": 2156,
    "recall_3": 0.8957894736842106,
    "precision_3": 0.7894248608534323,
    "f1-score_3": 0.8392504930966469
}