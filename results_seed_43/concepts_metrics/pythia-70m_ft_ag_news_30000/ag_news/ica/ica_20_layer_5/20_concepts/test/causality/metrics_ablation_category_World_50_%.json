{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        5,
        10
    ],
    "Global Absolute Accuracy change": -0.0039473772048950195,
    "Global Total Variation Distance with regard to original predictions": 0.020741943269968033,
    "Global label-flip rate": 0.020657895132899284,
    "number real samples_0": 1900,
    "true matches_0": 1704,
    "number predicted samples_0": 1852,
    "recall_0": 0.8968421052631579,
    "precision_0": 0.9200863930885529,
    "f1-score_0": 0.9083155650319829,
    "number real samples_1": 1900,
    "true matches_1": 1845,
    "number predicted samples_1": 1915,
    "recall_1": 0.9710526315789474,
    "precision_1": 0.9634464751958225,
    "f1-score_1": 0.9672346002621233,
    "number real samples_2": 1900,
    "true matches_2": 1659,
    "number predicted samples_2": 1899,
    "recall_2": 0.8731578947368421,
    "precision_2": 0.8736176935229067,
    "f1-score_2": 0.8733877336141089,
    "number real samples_3": 1900,
    "true matches_3": 1701,
    "number predicted samples_3": 1934,
    "recall_3": 0.8952631578947369,
    "precision_3": 0.8795243019648397,
    "f1-score_3": 0.8873239436619718
}