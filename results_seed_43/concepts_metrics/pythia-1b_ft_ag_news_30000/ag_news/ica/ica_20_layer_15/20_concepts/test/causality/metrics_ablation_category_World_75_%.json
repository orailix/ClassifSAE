{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        8,
        2,
        5
    ],
    "Global Absolute Accuracy change": -0.08828949928283691,
    "Global Total Variation Distance with regard to original predictions": 0.1134948655962944,
    "Global label-flip rate": 0.10526315867900848,
    "number real samples_0": 1900,
    "true matches_0": 1218,
    "number predicted samples_0": 1350,
    "recall_0": 0.6410526315789473,
    "precision_0": 0.9022222222222223,
    "f1-score_0": 0.7495384615384616,
    "number real samples_1": 1900,
    "true matches_1": 1872,
    "number predicted samples_1": 1904,
    "recall_1": 0.9852631578947368,
    "precision_1": 0.9831932773109243,
    "f1-score_1": 0.9842271293375394,
    "number real samples_2": 1900,
    "true matches_2": 1701,
    "number predicted samples_2": 1862,
    "recall_2": 0.8952631578947369,
    "precision_2": 0.9135338345864662,
    "f1-score_2": 0.9043062200956938,
    "number real samples_3": 1900,
    "true matches_3": 1683,
    "number predicted samples_3": 2484,
    "recall_3": 0.8857894736842106,
    "precision_3": 0.677536231884058,
    "f1-score_3": 0.7677919708029197
}