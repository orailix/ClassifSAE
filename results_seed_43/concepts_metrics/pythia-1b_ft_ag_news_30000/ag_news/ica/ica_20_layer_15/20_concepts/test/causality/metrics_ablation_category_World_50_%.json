{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        8,
        2
    ],
    "Global Absolute Accuracy change": -0.017763197422027588,
    "Global Total Variation Distance with regard to original predictions": 0.03529469668865204,
    "Global label-flip rate": 0.03236842155456543,
    "number real samples_0": 1900,
    "true matches_0": 1644,
    "number predicted samples_0": 1681,
    "recall_0": 0.8652631578947368,
    "precision_0": 0.9779892920880429,
    "f1-score_0": 0.9181792795308573,
    "number real samples_1": 1900,
    "true matches_1": 1872,
    "number predicted samples_1": 1903,
    "recall_1": 0.9852631578947368,
    "precision_1": 0.9837099316868103,
    "f1-score_1": 0.984485932158822,
    "number real samples_2": 1900,
    "true matches_2": 1695,
    "number predicted samples_2": 1839,
    "recall_2": 0.8921052631578947,
    "precision_2": 0.9216965742251223,
    "f1-score_2": 0.9066595346349292,
    "number real samples_3": 1900,
    "true matches_3": 1799,
    "number predicted samples_3": 2177,
    "recall_3": 0.9468421052631579,
    "precision_3": 0.8263665594855305,
    "f1-score_3": 0.8825116507235713
}