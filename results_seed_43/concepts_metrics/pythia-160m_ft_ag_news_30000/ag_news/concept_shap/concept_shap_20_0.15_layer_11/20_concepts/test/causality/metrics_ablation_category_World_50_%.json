{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        12,
        10,
        19
    ],
    "Global Absolute Accuracy change": -0.004868447780609131,
    "Global Total Variation Distance with regard to original predictions": 0.014446254819631577,
    "Global label-flip rate": 0.013421053066849709,
    "number real samples_0": 1900,
    "true matches_0": 1684,
    "number predicted samples_0": 1734,
    "recall_0": 0.8863157894736842,
    "precision_0": 0.9711649365628604,
    "f1-score_0": 0.9268024215740231,
    "number real samples_1": 1900,
    "true matches_1": 1870,
    "number predicted samples_1": 1934,
    "recall_1": 0.9842105263157894,
    "precision_1": 0.9669079627714581,
    "f1-score_1": 0.9754825247782994,
    "number real samples_2": 1900,
    "true matches_2": 1703,
    "number predicted samples_2": 1907,
    "recall_2": 0.8963157894736842,
    "precision_2": 0.8930256948086,
    "f1-score_2": 0.8946677173627529,
    "number real samples_3": 1900,
    "true matches_3": 1768,
    "number predicted samples_3": 2025,
    "recall_3": 0.9305263157894736,
    "precision_3": 0.8730864197530864,
    "f1-score_3": 0.900891719745223
}