{
    "category": "World",
    "Percentage ablation of the segment": 25,
    "Ablated features": [
        12
    ],
    "Global Absolute Accuracy change": -0.0003947615623474121,
    "Global Total Variation Distance with regard to original predictions": 0.001532643917016685,
    "Global label-flip rate": 0.0014473684132099152,
    "number real samples_0": 1900,
    "true matches_0": 1744,
    "number predicted samples_0": 1823,
    "recall_0": 0.9178947368421052,
    "precision_0": 0.9566648381788261,
    "f1-score_0": 0.9368788611334944,
    "number real samples_1": 1900,
    "true matches_1": 1866,
    "number predicted samples_1": 1923,
    "recall_1": 0.9821052631578947,
    "precision_1": 0.9703588143525741,
    "f1-score_1": 0.9761967041590374,
    "number real samples_2": 1900,
    "true matches_2": 1696,
    "number predicted samples_2": 1886,
    "recall_2": 0.8926315789473684,
    "precision_2": 0.8992576882290562,
    "f1-score_2": 0.8959323824617009,
    "number real samples_3": 1900,
    "true matches_3": 1753,
    "number predicted samples_3": 1968,
    "recall_3": 0.9226315789473685,
    "precision_3": 0.8907520325203252,
    "f1-score_3": 0.90641158221303
}