{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        12,
        10,
        19,
        11
    ],
    "Global Absolute Accuracy change": -0.06973683834075928,
    "Global Total Variation Distance with regard to original predictions": 0.08942023664712906,
    "Global label-flip rate": 0.08263158053159714,
    "number real samples_0": 1900,
    "true matches_0": 1182,
    "number predicted samples_0": 1212,
    "recall_0": 0.6221052631578947,
    "precision_0": 0.9752475247524752,
    "f1-score_0": 0.7596401028277635,
    "number real samples_1": 1900,
    "true matches_1": 1871,
    "number predicted samples_1": 1933,
    "recall_1": 0.9847368421052631,
    "precision_1": 0.9679255043973098,
    "f1-score_1": 0.9762588051134881,
    "number real samples_2": 1900,
    "true matches_2": 1708,
    "number predicted samples_2": 1982,
    "recall_2": 0.8989473684210526,
    "precision_2": 0.8617558022199798,
    "f1-score_2": 0.8799587841318909,
    "number real samples_3": 1900,
    "true matches_3": 1771,
    "number predicted samples_3": 2473,
    "recall_3": 0.9321052631578948,
    "precision_3": 0.7161342498989082,
    "f1-score_3": 0.8099702721243996
}