{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        10,
        17,
        16
    ],
    "Global Absolute Accuracy change": -0.03776317834854126,
    "Global Total Variation Distance with regard to original predictions": 0.06932198256254196,
    "Global label-flip rate": 0.06473684310913086,
    "number real samples_0": 1900,
    "true matches_0": 1509,
    "number predicted samples_0": 1563,
    "recall_0": 0.7942105263157895,
    "precision_0": 0.9654510556621881,
    "f1-score_0": 0.8714987005486572,
    "number real samples_1": 1900,
    "true matches_1": 1846,
    "number predicted samples_1": 1891,
    "recall_1": 0.9715789473684211,
    "precision_1": 0.9762030671602326,
    "f1-score_1": 0.9738855183328937,
    "number real samples_2": 1900,
    "true matches_2": 1763,
    "number predicted samples_2": 2332,
    "recall_2": 0.9278947368421052,
    "precision_2": 0.7560034305317325,
    "f1-score_2": 0.8331758034026466,
    "number real samples_3": 1900,
    "true matches_3": 1659,
    "number predicted samples_3": 1814,
    "recall_3": 0.8731578947368421,
    "precision_3": 0.9145534729878722,
    "f1-score_3": 0.8933764135702746
}