{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        5,
        2,
        12
    ],
    "Global Absolute Accuracy change": -0.06723684072494507,
    "Global Total Variation Distance with regard to original predictions": 0.08836784213781357,
    "Global label-flip rate": 0.07223684340715408,
    "number real samples_0": 1900,
    "true matches_0": 1232,
    "number predicted samples_0": 1281,
    "recall_0": 0.6484210526315789,
    "precision_0": 0.9617486338797814,
    "f1-score_0": 0.7745991826469664,
    "number real samples_1": 1900,
    "true matches_1": 1872,
    "number predicted samples_1": 1929,
    "recall_1": 0.9852631578947368,
    "precision_1": 0.9704510108864697,
    "f1-score_1": 0.9778009924262209,
    "number real samples_2": 1900,
    "true matches_2": 1690,
    "number predicted samples_2": 1874,
    "recall_2": 0.8894736842105263,
    "precision_2": 0.9018143009605123,
    "f1-score_2": 0.895601483836778,
    "number real samples_3": 1900,
    "true matches_3": 1762,
    "number predicted samples_3": 2516,
    "recall_3": 0.9273684210526316,
    "precision_3": 0.7003179650238474,
    "f1-score_3": 0.7980072463768116
}