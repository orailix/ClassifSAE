{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        7,
        8,
        15
    ],
    "Global Absolute Accuracy change": -0.01697373390197754,
    "Global Total Variation Distance with regard to original predictions": 0.04391024261713028,
    "Global label-flip rate": 0.03684210404753685,
    "number real samples_0": 1900,
    "true matches_0": 1662,
    "number predicted samples_0": 1703,
    "recall_0": 0.8747368421052631,
    "precision_0": 0.9759248385202584,
    "f1-score_0": 0.922564529558701,
    "number real samples_1": 1900,
    "true matches_1": 1876,
    "number predicted samples_1": 1924,
    "recall_1": 0.9873684210526316,
    "precision_1": 0.975051975051975,
    "f1-score_1": 0.9811715481171548,
    "number real samples_2": 1900,
    "true matches_2": 1714,
    "number predicted samples_2": 2042,
    "recall_2": 0.9021052631578947,
    "precision_2": 0.8393731635651323,
    "f1-score_2": 0.86960933536276,
    "number real samples_3": 1900,
    "true matches_3": 1732,
    "number predicted samples_3": 1931,
    "recall_3": 0.911578947368421,
    "precision_3": 0.8969445882962196,
    "f1-score_3": 0.9042025580788305
}