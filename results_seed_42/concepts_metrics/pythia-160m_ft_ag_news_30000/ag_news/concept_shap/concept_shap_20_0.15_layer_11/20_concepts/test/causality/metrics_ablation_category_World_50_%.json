{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        16,
        3,
        6,
        19
    ],
    "Global Absolute Accuracy change": -0.021184206008911133,
    "Global Total Variation Distance with regard to original predictions": 0.028045715764164925,
    "Global label-flip rate": 0.028421051800251007,
    "number real samples_0": 1900,
    "true matches_0": 1575,
    "number predicted samples_0": 1627,
    "recall_0": 0.8289473684210527,
    "precision_0": 0.968039336201598,
    "f1-score_0": 0.8931102920328892,
    "number real samples_1": 1900,
    "true matches_1": 1871,
    "number predicted samples_1": 1939,
    "recall_1": 0.9847368421052631,
    "precision_1": 0.9649303764827231,
    "f1-score_1": 0.9747330033862985,
    "number real samples_2": 1900,
    "true matches_2": 1704,
    "number predicted samples_2": 2006,
    "recall_2": 0.8968421052631579,
    "precision_2": 0.8494516450648056,
    "f1-score_2": 0.8725038402457759,
    "number real samples_3": 1900,
    "true matches_3": 1757,
    "number predicted samples_3": 2028,
    "recall_3": 0.9247368421052632,
    "precision_3": 0.866370808678501,
    "f1-score_3": 0.894602851323829
}