{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        3,
        2,
        15
    ],
    "Global Absolute Accuracy change": -0.0371052622795105,
    "Global Total Variation Distance with regard to original predictions": 0.06812308728694916,
    "Global label-flip rate": 0.06447368115186691,
    "number real samples_0": 1900,
    "true matches_0": 1512,
    "number predicted samples_0": 1563,
    "recall_0": 0.7957894736842105,
    "precision_0": 0.9673704414587332,
    "f1-score_0": 0.8732313023390125,
    "number real samples_1": 1900,
    "true matches_1": 1846,
    "number predicted samples_1": 1890,
    "recall_1": 0.9715789473684211,
    "precision_1": 0.9767195767195768,
    "f1-score_1": 0.974142480211082,
    "number real samples_2": 1900,
    "true matches_2": 1766,
    "number predicted samples_2": 2335,
    "recall_2": 0.9294736842105263,
    "precision_2": 0.7563169164882227,
    "f1-score_2": 0.8340023612750885,
    "number real samples_3": 1900,
    "true matches_3": 1658,
    "number predicted samples_3": 1812,
    "recall_3": 0.8726315789473684,
    "precision_3": 0.9150110375275938,
    "f1-score_3": 0.8933189655172414
}