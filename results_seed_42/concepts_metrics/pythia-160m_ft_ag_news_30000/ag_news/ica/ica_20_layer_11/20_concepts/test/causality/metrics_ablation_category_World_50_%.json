{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        3,
        2
    ],
    "Global Absolute Accuracy change": -0.03328949213027954,
    "Global Total Variation Distance with regard to original predictions": 0.06095403805375099,
    "Global label-flip rate": 0.057500001043081284,
    "number real samples_0": 1900,
    "true matches_0": 1518,
    "number predicted samples_0": 1565,
    "recall_0": 0.7989473684210526,
    "precision_0": 0.9699680511182108,
    "f1-score_0": 0.8761904761904761,
    "number real samples_1": 1900,
    "true matches_1": 1844,
    "number predicted samples_1": 1889,
    "recall_1": 0.9705263157894737,
    "precision_1": 0.9761778718898888,
    "f1-score_1": 0.9733438902084983,
    "number real samples_2": 1900,
    "true matches_2": 1726,
    "number predicted samples_2": 2230,
    "recall_2": 0.9084210526315789,
    "precision_2": 0.7739910313901345,
    "f1-score_2": 0.8358353510895883,
    "number real samples_3": 1900,
    "true matches_3": 1723,
    "number predicted samples_3": 1916,
    "recall_3": 0.9068421052631579,
    "precision_3": 0.8992693110647182,
    "f1-score_3": 0.9030398322851152
}