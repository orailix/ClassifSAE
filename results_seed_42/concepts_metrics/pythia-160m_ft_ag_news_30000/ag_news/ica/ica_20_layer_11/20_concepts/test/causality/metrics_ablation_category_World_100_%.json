{
    "category": "World",
    "Percentage ablation of the segment": 100,
    "Ablated features": [
        3,
        2,
        15,
        12
    ],
    "Global Absolute Accuracy change": -0.051447391510009766,
    "Global Total Variation Distance with regard to original predictions": 0.0883675217628479,
    "Global label-flip rate": 0.0813157930970192,
    "number real samples_0": 1900,
    "true matches_0": 1509,
    "number predicted samples_0": 1558,
    "recall_0": 0.7942105263157895,
    "precision_0": 0.9685494223363287,
    "f1-score_0": 0.8727588201272412,
    "number real samples_1": 1900,
    "true matches_1": 1846,
    "number predicted samples_1": 1891,
    "recall_1": 0.9715789473684211,
    "precision_1": 0.9762030671602326,
    "f1-score_1": 0.9738855183328937,
    "number real samples_2": 1900,
    "true matches_2": 1728,
    "number predicted samples_2": 2346,
    "recall_2": 0.9094736842105263,
    "precision_2": 0.7365728900255755,
    "f1-score_2": 0.8139425341497879,
    "number real samples_3": 1900,
    "true matches_3": 1590,
    "number predicted samples_3": 1805,
    "recall_3": 0.8368421052631579,
    "precision_3": 0.8808864265927978,
    "f1-score_3": 0.8582995951417004
}