{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        4,
        14
    ],
    "Global Absolute Accuracy change": -0.02736842632293701,
    "Global Total Variation Distance with regard to original predictions": 0.038586072623729706,
    "Global label-flip rate": 0.03105263225734234,
    "number real samples_0": 1900,
    "true matches_0": 1522,
    "number predicted samples_0": 1577,
    "recall_0": 0.8010526315789473,
    "precision_0": 0.9651236525047558,
    "f1-score_0": 0.8754673569168824,
    "number real samples_1": 1900,
    "true matches_1": 1867,
    "number predicted samples_1": 1928,
    "recall_1": 0.9826315789473684,
    "precision_1": 0.9683609958506224,
    "f1-score_1": 0.9754440961337513,
    "number real samples_2": 1900,
    "true matches_2": 1712,
    "number predicted samples_2": 2126,
    "recall_2": 0.9010526315789473,
    "precision_2": 0.8052681091251176,
    "f1-score_2": 0.8504719324391454,
    "number real samples_3": 1900,
    "true matches_3": 1747,
    "number predicted samples_3": 1969,
    "recall_3": 0.9194736842105263,
    "precision_3": 0.8872524123920772,
    "f1-score_3": 0.9030757301628327
}