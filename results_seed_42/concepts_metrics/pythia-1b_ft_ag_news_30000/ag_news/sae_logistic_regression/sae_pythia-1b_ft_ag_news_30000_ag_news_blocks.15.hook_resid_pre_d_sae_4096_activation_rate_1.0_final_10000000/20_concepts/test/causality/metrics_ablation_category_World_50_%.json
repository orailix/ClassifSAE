{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        3263
    ],
    "Global Absolute Accuracy change": -0.0005263090133666992,
    "Global Total Variation Distance with regard to original predictions": 0.003672455670312047,
    "Global label-flip rate": 0.0021052630618214607,
    "number real samples_0": 1900,
    "true matches_0": 1759,
    "number predicted samples_0": 1821,
    "recall_0": 0.9257894736842105,
    "precision_0": 0.9659527732015376,
    "f1-score_0": 0.945444772910508,
    "number real samples_1": 1900,
    "true matches_1": 1882,
    "number predicted samples_1": 1932,
    "recall_1": 0.9905263157894737,
    "precision_1": 0.974120082815735,
    "f1-score_1": 0.9822546972860126,
    "number real samples_2": 1900,
    "true matches_2": 1687,
    "number predicted samples_2": 1827,
    "recall_2": 0.8878947368421053,
    "precision_2": 0.9233716475095786,
    "f1-score_2": 0.9052857526160452,
    "number real samples_3": 1900,
    "true matches_3": 1790,
    "number predicted samples_3": 2020,
    "recall_3": 0.9421052631578948,
    "precision_3": 0.8861386138613861,
    "f1-score_3": 0.913265306122449
}