{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        3263,
        2370
    ],
    "Global Absolute Accuracy change": -0.003289461135864258,
    "Global Total Variation Distance with regard to original predictions": 0.015012622810900211,
    "Global label-flip rate": 0.008552631363272667,
    "number real samples_0": 1900,
    "true matches_0": 1725,
    "number predicted samples_0": 1772,
    "recall_0": 0.9078947368421053,
    "precision_0": 0.9734762979683973,
    "f1-score_0": 0.9395424836601308,
    "number real samples_1": 1900,
    "true matches_1": 1884,
    "number predicted samples_1": 1942,
    "recall_1": 0.991578947368421,
    "precision_1": 0.9701338825952626,
    "f1-score_1": 0.9807391983342009,
    "number real samples_2": 1900,
    "true matches_2": 1689,
    "number predicted samples_2": 1839,
    "recall_2": 0.8889473684210526,
    "precision_2": 0.9184339314845025,
    "f1-score_2": 0.9034501203530356,
    "number real samples_3": 1900,
    "true matches_3": 1799,
    "number predicted samples_3": 2047,
    "recall_3": 0.9468421052631579,
    "precision_3": 0.878847093307279,
    "f1-score_3": 0.9115784139853053
}