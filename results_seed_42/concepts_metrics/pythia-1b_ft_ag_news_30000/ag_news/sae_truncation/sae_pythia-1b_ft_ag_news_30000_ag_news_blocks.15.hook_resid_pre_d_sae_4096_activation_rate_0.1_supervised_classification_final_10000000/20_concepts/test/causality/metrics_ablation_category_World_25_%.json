{
    "category": "World",
    "Percentage ablation of the segment": 25,
    "Ablated features": [
        14
    ],
    "Global Absolute Accuracy change": -0.02960526943206787,
    "Global Total Variation Distance with regard to original predictions": 0.04127390682697296,
    "Global label-flip rate": 0.030921053141355515,
    "number real samples_0": 1900,
    "true matches_0": 1555,
    "number predicted samples_0": 1608,
    "recall_0": 0.8184210526315789,
    "precision_0": 0.9670398009950248,
    "f1-score_0": 0.88654503990878,
    "number real samples_1": 1900,
    "true matches_1": 1840,
    "number predicted samples_1": 1859,
    "recall_1": 0.968421052631579,
    "precision_1": 0.9897794513179129,
    "f1-score_1": 0.9789837722798617,
    "number real samples_2": 1900,
    "true matches_2": 1740,
    "number predicted samples_2": 2202,
    "recall_2": 0.9157894736842105,
    "precision_2": 0.7901907356948229,
    "f1-score_2": 0.8483666504144319,
    "number real samples_3": 1900,
    "true matches_3": 1763,
    "number predicted samples_3": 1931,
    "recall_3": 0.9278947368421052,
    "precision_3": 0.9129984464008286,
    "f1-score_3": 0.9203863221091099
}