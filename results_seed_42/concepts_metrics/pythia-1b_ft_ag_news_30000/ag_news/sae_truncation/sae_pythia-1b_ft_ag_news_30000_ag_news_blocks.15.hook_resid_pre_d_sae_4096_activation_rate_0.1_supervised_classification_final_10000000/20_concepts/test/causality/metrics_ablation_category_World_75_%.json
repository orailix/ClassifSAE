{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        14,
        4,
        10
    ],
    "Global Absolute Accuracy change": -0.13184213638305664,
    "Global Total Variation Distance with regard to original predictions": 0.1367385983467102,
    "Global label-flip rate": 0.14249999821186066,
    "number real samples_0": 1900,
    "true matches_0": 754,
    "number predicted samples_0": 760,
    "recall_0": 0.3968421052631579,
    "precision_0": 0.9921052631578947,
    "f1-score_0": 0.5669172932330827,
    "number real samples_1": 1900,
    "true matches_1": 1840,
    "number predicted samples_1": 1859,
    "recall_1": 0.968421052631579,
    "precision_1": 0.9897794513179129,
    "f1-score_1": 0.9789837722798617,
    "number real samples_2": 1900,
    "true matches_2": 1764,
    "number predicted samples_2": 3049,
    "recall_2": 0.9284210526315789,
    "precision_2": 0.578550344375205,
    "f1-score_2": 0.7128712871287128,
    "number real samples_3": 1900,
    "true matches_3": 1763,
    "number predicted samples_3": 1932,
    "recall_3": 0.9278947368421052,
    "precision_3": 0.9125258799171843,
    "f1-score_3": 0.9201461377870563
}