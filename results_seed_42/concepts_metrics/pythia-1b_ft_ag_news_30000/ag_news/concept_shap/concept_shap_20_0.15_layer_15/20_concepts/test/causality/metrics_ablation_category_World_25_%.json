{
    "category": "World",
    "Percentage ablation of the segment": 25,
    "Ablated features": [
        12,
        11,
        10
    ],
    "Global Absolute Accuracy change": -0.0076315999031066895,
    "Global Total Variation Distance with regard to original predictions": 0.01774437353014946,
    "Global label-flip rate": 0.015263157896697521,
    "number real samples_0": 1900,
    "true matches_0": 1689,
    "number predicted samples_0": 1732,
    "recall_0": 0.8889473684210526,
    "precision_0": 0.9751732101616628,
    "f1-score_0": 0.9300660792951543,
    "number real samples_1": 1900,
    "true matches_1": 1744,
    "number predicted samples_1": 1890,
    "recall_1": 0.9178947368421052,
    "precision_1": 0.9227513227513228,
    "f1-score_1": 0.9203166226912928,
    "number real samples_2": 1900,
    "true matches_2": 1478,
    "number predicted samples_2": 1678,
    "recall_2": 0.7778947368421053,
    "precision_2": 0.8808104886769964,
    "f1-score_2": 0.8261598658468418,
    "number real samples_3": 1900,
    "true matches_3": 1781,
    "number predicted samples_3": 2300,
    "recall_3": 0.9373684210526316,
    "precision_3": 0.7743478260869565,
    "f1-score_3": 0.8480952380952381
}