{
    "category": "World",
    "Percentage ablation of the segment": 100,
    "Ablated features": [
        18,
        19,
        7,
        5
    ],
    "Global Absolute Accuracy change": -0.11302632093429565,
    "Global Total Variation Distance with regard to original predictions": 0.14748050272464752,
    "Global label-flip rate": 0.13526315987110138,
    "number real samples_0": 1900,
    "true matches_0": 1214,
    "number predicted samples_0": 1444,
    "recall_0": 0.6389473684210526,
    "precision_0": 0.8407202216066482,
    "f1-score_0": 0.7260765550239234,
    "number real samples_1": 1900,
    "true matches_1": 1866,
    "number predicted samples_1": 1893,
    "recall_1": 0.9821052631578947,
    "precision_1": 0.9857369255150554,
    "f1-score_1": 0.9839177432111784,
    "number real samples_2": 1900,
    "true matches_2": 1677,
    "number predicted samples_2": 1881,
    "recall_2": 0.8826315789473684,
    "precision_2": 0.8915470494417863,
    "f1-score_2": 0.8870669135149432,
    "number real samples_3": 1900,
    "true matches_3": 1529,
    "number predicted samples_3": 2382,
    "recall_3": 0.8047368421052632,
    "precision_3": 0.6418975650713686,
    "f1-score_3": 0.7141522652965904
}