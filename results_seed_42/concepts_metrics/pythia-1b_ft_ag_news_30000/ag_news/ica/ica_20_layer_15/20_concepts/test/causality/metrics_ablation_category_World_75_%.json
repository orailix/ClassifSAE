{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        18,
        19,
        7
    ],
    "Global Absolute Accuracy change": -0.09355264902114868,
    "Global Total Variation Distance with regard to original predictions": 0.12711776793003082,
    "Global label-flip rate": 0.11263158172369003,
    "number real samples_0": 1900,
    "true matches_0": 1265,
    "number predicted samples_0": 1471,
    "recall_0": 0.6657894736842105,
    "precision_0": 0.8599592114208022,
    "f1-score_0": 0.7505191337881933,
    "number real samples_1": 1900,
    "true matches_1": 1869,
    "number predicted samples_1": 1898,
    "recall_1": 0.9836842105263158,
    "precision_1": 0.9847207586933614,
    "f1-score_1": 0.9842022116903634,
    "number real samples_2": 1900,
    "true matches_2": 1689,
    "number predicted samples_2": 1841,
    "recall_2": 0.8889473684210526,
    "precision_2": 0.9174361759913091,
    "f1-score_2": 0.9029671210906175,
    "number real samples_3": 1900,
    "true matches_3": 1611,
    "number predicted samples_3": 2390,
    "recall_3": 0.8478947368421053,
    "precision_3": 0.6740585774058577,
    "f1-score_3": 0.751048951048951
}