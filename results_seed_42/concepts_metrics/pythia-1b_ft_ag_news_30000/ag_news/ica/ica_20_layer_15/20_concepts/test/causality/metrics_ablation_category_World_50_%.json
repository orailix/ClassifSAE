{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        18,
        19
    ],
    "Global Absolute Accuracy change": -0.027236878871917725,
    "Global Total Variation Distance with regard to original predictions": 0.05284347012639046,
    "Global label-flip rate": 0.04710526391863823,
    "number real samples_0": 1900,
    "true matches_0": 1580,
    "number predicted samples_0": 1612,
    "recall_0": 0.8315789473684211,
    "precision_0": 0.9801488833746899,
    "f1-score_0": 0.8997722095671982,
    "number real samples_1": 1900,
    "true matches_1": 1869,
    "number predicted samples_1": 1896,
    "recall_1": 0.9836842105263158,
    "precision_1": 0.9857594936708861,
    "f1-score_1": 0.9847207586933615,
    "number real samples_2": 1900,
    "true matches_2": 1678,
    "number predicted samples_2": 1812,
    "recall_2": 0.8831578947368421,
    "precision_2": 0.9260485651214128,
    "f1-score_2": 0.9040948275862069,
    "number real samples_3": 1900,
    "true matches_3": 1811,
    "number predicted samples_3": 2280,
    "recall_3": 0.9531578947368421,
    "precision_3": 0.7942982456140351,
    "f1-score_3": 0.8665071770334928
}