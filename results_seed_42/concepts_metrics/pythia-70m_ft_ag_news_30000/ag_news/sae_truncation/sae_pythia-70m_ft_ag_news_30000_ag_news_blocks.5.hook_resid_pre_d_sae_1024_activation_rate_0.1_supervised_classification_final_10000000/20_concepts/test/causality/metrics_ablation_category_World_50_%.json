{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        9,
        17,
        14
    ],
    "Global Absolute Accuracy change": -0.04842102527618408,
    "Global Total Variation Distance with regard to original predictions": 0.05914408341050148,
    "Global label-flip rate": 0.05921052768826485,
    "number real samples_0": 1900,
    "true matches_0": 1299,
    "number predicted samples_0": 1352,
    "recall_0": 0.6836842105263158,
    "precision_0": 0.9607988165680473,
    "f1-score_0": 0.7988929889298894,
    "number real samples_1": 1900,
    "true matches_1": 1868,
    "number predicted samples_1": 2336,
    "recall_1": 0.9831578947368421,
    "precision_1": 0.7996575342465754,
    "f1-score_1": 0.8819641170915958,
    "number real samples_2": 1900,
    "true matches_2": 1641,
    "number predicted samples_2": 1889,
    "recall_2": 0.8636842105263158,
    "precision_2": 0.868713605082054,
    "f1-score_2": 0.8661916072842438,
    "number real samples_3": 1900,
    "true matches_3": 1732,
    "number predicted samples_3": 2023,
    "recall_3": 0.911578947368421,
    "precision_3": 0.8561542263964409,
    "f1-score_3": 0.8829977058373694
}