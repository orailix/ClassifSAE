{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        9,
        17,
        14,
        3
    ],
    "Global Absolute Accuracy change": -0.10763156414031982,
    "Global Total Variation Distance with regard to original predictions": 0.12740682065486908,
    "Global label-flip rate": 0.12289473414421082,
    "number real samples_0": 1900,
    "true matches_0": 842,
    "number predicted samples_0": 868,
    "recall_0": 0.4431578947368421,
    "precision_0": 0.9700460829493087,
    "f1-score_0": 0.6083815028901733,
    "number real samples_1": 1900,
    "true matches_1": 1869,
    "number predicted samples_1": 2779,
    "recall_1": 0.9836842105263158,
    "precision_1": 0.672544080604534,
    "f1-score_1": 0.7988886514212439,
    "number real samples_2": 1900,
    "true matches_2": 1643,
    "number predicted samples_2": 1910,
    "recall_2": 0.8647368421052631,
    "precision_2": 0.8602094240837697,
    "f1-score_2": 0.8624671916010499,
    "number real samples_3": 1900,
    "true matches_3": 1736,
    "number predicted samples_3": 2043,
    "recall_3": 0.9136842105263158,
    "precision_3": 0.8497307880567793,
    "f1-score_3": 0.8805478062389044
}