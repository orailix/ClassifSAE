{
    "category": "World",
    "Percentage ablation of the segment": 75,
    "Ablated features": [
        11,
        13,
        0,
        3
    ],
    "Global Absolute Accuracy change": -0.04118424654006958,
    "Global Total Variation Distance with regard to original predictions": 0.08158618956804276,
    "Global label-flip rate": 0.08013157546520233,
    "number real samples_0": 1900,
    "true matches_0": 1492,
    "number predicted samples_0": 1628,
    "recall_0": 0.7852631578947369,
    "precision_0": 0.9164619164619164,
    "f1-score_0": 0.8458049886621315,
    "number real samples_1": 1900,
    "true matches_1": 1817,
    "number predicted samples_1": 1883,
    "recall_1": 0.9563157894736842,
    "precision_1": 0.9649495485926712,
    "f1-score_1": 0.9606132698916204,
    "number real samples_2": 1900,
    "true matches_2": 1605,
    "number predicted samples_2": 2105,
    "recall_2": 0.8447368421052631,
    "precision_2": 0.7624703087885986,
    "f1-score_2": 0.801498127340824,
    "number real samples_3": 1900,
    "true matches_3": 1712,
    "number predicted samples_3": 1984,
    "recall_3": 0.9010526315789473,
    "precision_3": 0.8629032258064516,
    "f1-score_3": 0.8815653964984552
}