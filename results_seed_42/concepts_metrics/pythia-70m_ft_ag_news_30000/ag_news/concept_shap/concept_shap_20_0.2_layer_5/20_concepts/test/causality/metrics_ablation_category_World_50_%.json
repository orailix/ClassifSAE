{
    "category": "World",
    "Percentage ablation of the segment": 50,
    "Ablated features": [
        19,
        14,
        9
    ],
    "Global Absolute Accuracy change": -0.021447360515594482,
    "Global Total Variation Distance with regard to original predictions": 0.03503495082259178,
    "Global label-flip rate": 0.03368420898914337,
    "number real samples_0": 1900,
    "true matches_0": 1518,
    "number predicted samples_0": 1588,
    "recall_0": 0.7989473684210526,
    "precision_0": 0.9559193954659949,
    "f1-score_0": 0.8704128440366972,
    "number real samples_1": 1900,
    "true matches_1": 1859,
    "number predicted samples_1": 1973,
    "recall_1": 0.978421052631579,
    "precision_1": 0.9422199695894576,
    "f1-score_1": 0.9599793441776401,
    "number real samples_2": 1900,
    "true matches_2": 1638,
    "number predicted samples_2": 1894,
    "recall_2": 0.8621052631578947,
    "precision_2": 0.8648363252375924,
    "f1-score_2": 0.8634686346863468,
    "number real samples_3": 1900,
    "true matches_3": 1749,
    "number predicted samples_3": 2145,
    "recall_3": 0.9205263157894736,
    "precision_3": 0.8153846153846154,
    "f1-score_3": 0.8647713226205191
}