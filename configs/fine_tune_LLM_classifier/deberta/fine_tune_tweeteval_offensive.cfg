[main]
model = deberta
model_path=microsoft/deberta-v3-large
dataset = tweeteval_offensive

[training_args]
max_steps=10000
per_device_train_batch_size=4
save_steps=5000
warmup_ratio=0.05
max_grad_norm = 1.0
evaluation_strategy=no
learning_rate=2e-6
lr_scheduler_type=cosine
weight_decay=0.01
fp16=True
optim=adamw_bnb_8bit 
seed=42