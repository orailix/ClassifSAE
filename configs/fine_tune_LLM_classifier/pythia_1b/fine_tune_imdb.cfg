[main]
model = pythia-1b
model_path=EleutherAI/pythia-1b
dataset = imdb
eos=False

[training_args]
max_steps=30000
per_device_train_batch_size=2
save_steps=10000
warmup_ratio=0.05
max_grad_norm = 1.0
evaluation_strategy=no
learning_rate=2e-6
lr_scheduler_type=cosine
weight_decay=0.01
fp16=True
optim=adamw_bnb_8bit 
seed=42