[main]
model=bert
model_path=bert-base-uncased
dataset=ag_news
task=sae_training

[version]
finetuned=True
latest_version = False
checkpoint_version=30000
dataset_tuned_on=ag_news

[task_args]
activation_fn=topk
topk=10
training_tokens=10000000
len_epoch=120000
d_in=768
d_sae=1536
hook_layer=12
expansion_factor=0
store_batch_size_prompts=4
n_batches_in_buffer=6000
save_label=True
prompt_tuning=False
train_batch_size_tokens=500
wandb_log_frequency=1
seed=42
use_ghost_grads=True
decoder_orthogonal_init=False
init_encoder_as_decoder_transpose=True
b_dec_init_method=zeros
l1_coefficient=0.
mse_loss_normalization=dense_batch
normalize_sae_decoder=True
lmbda_mse=1
lmbda_activation_rate=0.
lmbda_vcr=0
lmbda_decoder_columns_similarity=0.
lmbda_classifier=0
num_classifier_features=20
nb_classes=4
feature_activation_rate=[1.]
lr=5e-5
lr_scheduler_name=cosineannealing
lr_end=5e-7
feature_sampling_window=100
dead_feature_window=100
dead_feature_threshold=1e-4